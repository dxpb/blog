Today I will be walking through my process as I try to understand how dxpb is broken. The author may as well be a different person - it has been at least two months since I touched this code.

The code in question is the dxpb frontend. This piece sits as the public gateway, and has a variety of jobs, all relating to making sure the grapher knows about downstream truth, that the workers know what the grapher wants them to do, and that the log messages from xbps-src get filed.

Aside: the log messages are the keepalive pings from the builders to the frontend, every two seconds just letting the frontend know the job is still underway.

So there was an odd behavior where it seemed there was a disconnect between what the grapher wanted built and what the workers could do (arch mismatches, reassigning builders otherwise tasked properly, that sort of thing). After two months of procrastinating and testing the builder for correctness (shoutout to lemmi for breaking the builder, thank you), I now know I must fiddle with the frontend.

Ah well.

I'll be writing as I work on this. I have an hour left to my flight, let's make it a good hour. Hopefully by writing this blog while debugging, my thoughts will be more ordered.

Before I started writing, I had decided to remove all the double-checks that grapher-like messages were indeed going only to the grapher. They were redundant, with asserts() already sprinkled to make sure only a registered grapher ever gets into that corner of the state machine anyway. I also simplified some logic, such as the decision whether or not to forward messages to the grapher. Since this system supports the grapher vanishing, showing up late, or, in theory, restarting, all messages to the grapher come in the form of memos.

The memo struct is simple:

```
struct memo {
	int msgid;
	const char *hostarch;
	const char *targetarch;
	uint16_t addr;
	uint16_t cost;
	uint32_t check;
	uint8_t iscross;
	enum end_status cause;
	char *pkgname;
	char *version;
	char *arch;
};
```

This can hold all the possible information I may want to get to the grapher, or from the grapher. The memos are popped on a list to be consumed later. Previous behavior: max 5 memos would get out before I decided to let the poor state machine have another go. Except, I never really got back to sending memos, so a memo lifespan could be much longer than the millisecond it would take to send the grapher a memo. So the limit of 5 memos is gone, now the grapher will be greedy and get all the memos it can handle at once.

I hope that solves some consistency problems, but let's keep digging.

When we send workers a job (package name, version, arch) to build, there is a line:
```
assert(zlist_size(self->assign_addrs) == 1);
```
It's probably possible for the grapher to be faster than our loop, so let's make a one-character change, just to enforce all the consistency we actually care about.
```
assert(zlist_size(self->assign_addrs) >= 1);
```

The frontend wasn't asserting, but this is a change that seems good.

Any connection to or from the frontend can be in one of three roles: grapher, filer, or worker. The filer is the disk storage (think: logs). So now when we enter the states for worker or grapher or filer, we assert to make sure we are not also one of the other things. Invert one assertion per connection type:

```
assert(self->server->grapher != self);
assert(self->server->storage != self);
assert(!self->worker);
```

Tiny change, but just helps keep me sane to have all three checked in one place when entering the states where that's important.

There is a chance for confusion with address handling. Workers can have N addresses (each a different capability, such as a different arch), and each layer of translation has a local address. That local address must map uniquely to a downstream connection, and that downstream connection will have its own address for further addressing madness. It's similar to a hotel room, except that the number changes every time you progress: front desk tells you room "613," you take the room number to the elevator, the elevator operator takes you to the correct floor, and gives you a new number, "18," which is actually the number on your hotel room door, then you wander down to the door.

Anyway, the address handling is confusing, with things like myaddr vs. addr to refer to local vs. remote (downstream) addresses. Tell the grapher about myaddr, and tell the worker about addr. The handling was correct last I looked, but it's always worth double-checking. I moved more and more into the `bworker` module, to handle it consistently for me. The addressing scheme is nice and doesn't require me to establish such things as static workers or limits on workers per arch, or whatever. It also allows for, if you continue the analogy, multiple numbers on a single hotel room door. "Which room did you come to?" asks the person on the inside, and you tell her "18" and she says "Ah, you are in bed number 3" but also documents your arrival, and makes a decision about whether the remaining few beds can handle more people. She can now make smart decisions about the rest of the numbers on her door, knowing about your arrival. More on that in a later release.

The address handling here makes sense. The myaddr is used to tell the grapher about workers, and not backwards. When the worker is told of a job, the structs are indeed properly populated. I'll go check that the memos to the workers are properly set.

When we tell workers of jobs, we say (downstream address):
`pkggraph_msg_set_addr(self->message, wrkr->addr);`
When we translate messages (JOB_ENDED, ICANHELP, FORGET_ABOUT_ME) to the grapher (upstream address):
`memo->addr = wrkr->myaddr;`

When we check the bworker functions, we learn:
```
bworker_subgroup_insert(struct bworksubgroup *grp, uint16_t addr, /* snip */) {
/* snip */
	bworker_new(j, addr, /*snip */);
	/* snip */
}
```

and in `bworker_new`:
```
bworker_new(uint16_t myaddr, uint16_t addr, /* snip */) {
/* snip */
	return bworker_reinit(retVal, myaddr, addr);
}
```

And then, finally:
```
bworker_reinit(struct bworker *wrkr, uint16_t myaddr, uint16_t addr, /* snip */) {
	wrkr->addr = addr;
	wrkr->myaddr = myaddr;
	/* snip */
}
```

So the downstream address is the `addr` variable, and `myaddr` should always be used when dealing with upstream. This is consistent with our usage.

So with that we will give this codebase another try, see if these small changes have fixed our problems.
